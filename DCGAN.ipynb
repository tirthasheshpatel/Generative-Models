{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlw8LoDkYbQDCMovm91PRr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirthasheshpatel/Generative-Models/blob/gans/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCWcptevjsfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "00cbb5e1-618c-471b-f6a6-e98bbacfaeb3"
      },
      "source": [
        "%%shell\n",
        "cd /content\n",
        "flag=0\n",
        "for FILE in `ls -a`\n",
        "do\n",
        "    if [[ $FILE == \"Generative-Models\" ]]\n",
        "    then\n",
        "        cd $FILE\n",
        "        git pull origin master\n",
        "        flag=1\n",
        "        break\n",
        "    fi\n",
        "done\n",
        "\n",
        "if [[ flag -ne 1 ]]\n",
        "then\n",
        "    git clone https://github.com/tirthasheshpatel/Generative-Models.git\n",
        "    cd \"Generative-Models\"\n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/tirthasheshpatel/Generative-Models\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFEk4q1YkZ0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3500b845-f04c-412f-8adf-e7ad9202c784"
      },
      "source": [
        "%cd /content/Generative-Models\n",
        "%tensorflow_version 1.x\n",
        "import functools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import Input\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import InputLayer, Dense, Lambda, Reshape\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "\n",
        "# Start tf session so we can run code.\n",
        "sess = tf.InteractiveSession()\n",
        "# Connect keras to the created session.\n",
        "K.set_session(sess)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Generative-Models\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhUX0oBGlXAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(gen_label, true_label):\n",
        "    disc_loss = tf.reduce_mean(tf.log(true_label) + tf.log(1 - gen_label))\n",
        "    return -disc_loss\n",
        "\n",
        "def generator_loss(gen_label):\n",
        "    gen_loss = tf.reduce_mean(tf.log(gen_label))\n",
        "    return -gen_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBwLcTuhNAyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "image_dims = 784 # Number of pixels in MNIST images.\n",
        "latent_dims = 3 # d, dimensionality of the latent code t.\n",
        "intermediate_dims = 128 # Size of the hidden layer.\n",
        "epochs = 20\n",
        "lr_disc = 0.00002\n",
        "lr_gen = 0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHGzR1A5k-VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_discriminator(image_dims):\n",
        "    model = Sequential(name=\"discriminator\")\n",
        "    model.add(InputLayer([image_dims]))\n",
        "    model.add(Dense(intermediate_dims, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def get_generator(latent_dims, image_dims):\n",
        "    model = Sequential(name=\"generator\")\n",
        "    model.add(InputLayer([latent_dims]))\n",
        "    model.add(Dense(intermediate_dims, activation='relu'))\n",
        "    model.add(Dense(image_dims, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def get_sample(sample_shape):\n",
        "    samples = K.random_normal(sample_shape)\n",
        "    return samples\n",
        "\n",
        "get_sample = functools.partial(get_sample, sample_shape=[batch_size, latent_dims])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-zf7by5NEBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3a819b60-edc2-4f5e-b41a-e734e55f842c"
      },
      "source": [
        "discriminator = get_discriminator(image_dims)\n",
        "generator = get_generator(latent_dims, image_dims)\n",
        "sampling = Lambda(lambda x: get_sample())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvMdkpHGRib1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Input(batch_shape=(batch_size, image_dims))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6JtXXIsNufu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create and compile our discriminator first\n",
        "true_label = discriminator(x)\n",
        "sample_z = sampling(x)\n",
        "gen_sample = generator(sample_z)\n",
        "gen_label = discriminator(gen_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X6WCJPrRvF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc_loss = discriminator_loss(gen_label, true_label)\n",
        "discriminator_model = Model(x, gen_label)\n",
        "\n",
        "discriminator_model.compile(optimizer=keras.optimizers.Adam(lr=lr_disc), loss=lambda *args, **kwargs: disc_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymdbICuDSBva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create and compile our generator now\n",
        "sample_z = sampling(x)\n",
        "gen_sample = generator(sample_z)\n",
        "gen_label = discriminator(gen_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF3lc5_bSjOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_loss = generator_loss(gen_label)\n",
        "generator_model = Model(x, gen_sample)\n",
        "\n",
        "generator_model.compile(optimizer=keras.optimizers.Adam(lr=lr_gen), loss=lambda *args, **kwargs: gen_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K30mnXqITn5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "91650c46-3024-4c18-81f9-fc79ab92293d"
      },
      "source": [
        "discriminator_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (100, 784)                0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (100, 3)                  0         \n",
            "_________________________________________________________________\n",
            "generator (Sequential)       multiple                  101648    \n",
            "_________________________________________________________________\n",
            "discriminator (Sequential)   multiple                  100609    \n",
            "=================================================================\n",
            "Total params: 202,257\n",
            "Trainable params: 202,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORcpP9w3VQXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "12d08e28-c6e2-4106-cb75-f76f62dafdd9"
      },
      "source": [
        "generator_model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (100, 784)                0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (100, 3)                  0         \n",
            "_________________________________________________________________\n",
            "generator (Sequential)       multiple                  101648    \n",
            "=================================================================\n",
            "Total params: 101,648\n",
            "Trainable params: 101,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKRySgZmVsaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the VAE on MNIST digits\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# One hot encoding.\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHUClkiXVTZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "outputId": "bf23c914-77af-44c4-cb05-6b21d4b5f97f"
      },
      "source": [
        "for _ in range(100):\n",
        "    print(\"Trining Discriminator\")\n",
        "    hist = discriminator_model.fit(x=x_train, y=x_train,\n",
        "                                    shuffle=True,\n",
        "                                    epochs=1,\n",
        "                                    batch_size=batch_size,\n",
        "                                    validation_data=(x_test, x_test),\n",
        "                                    verbose=2)\n",
        "    print(\"Training Generator\")\n",
        "    hist = generator_model.fit(x=x_train, y=x_train,\n",
        "                                shuffle=True,\n",
        "                                epochs=1,\n",
        "                                batch_size=batch_size,\n",
        "                                validation_data=(x_test, x_test),\n",
        "                                verbose=2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trining Discriminator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.0013 - val_loss: 9.9162e-04\n",
            "Training Generator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 1s - loss: 0.2706 - val_loss: 0.0033\n",
            "Trining Discriminator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.0971 - val_loss: 0.0150\n",
            "Training Generator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 1s - loss: 0.1604 - val_loss: 0.0035\n",
            "Trining Discriminator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.2390 - val_loss: 0.0660\n",
            "Training Generator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 1s - loss: 0.1168 - val_loss: 0.0037\n",
            "Trining Discriminator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 2s - loss: 0.3514 - val_loss: 0.0935\n",
            "Training Generator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 1s - loss: 0.1278 - val_loss: 0.0038\n",
            "Trining Discriminator\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f18933d7bab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                     verbose=2)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Generator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     hist = generator_model.fit(x=x_train, y=x_train,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                                          verbose=0)\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bv7SoTk9Yr_B",
        "colab": {}
      },
      "source": [
        "generated = sess.run(gen_sample, feed_dict={})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-oF5dbYYgCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftiXGao0Y37k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "12b11df0-837c-4717-d35b-cc2d446ed4fe"
      },
      "source": [
        "plt.imshow(generated[0].reshape(28, 28));"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlkyhkyxkEbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}